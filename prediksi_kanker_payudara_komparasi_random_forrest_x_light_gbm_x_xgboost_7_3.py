# -*- coding: utf-8 -*-
"""Prediksi_kanker_payudara_Komparasi_Random_Forrest_x_Light_GBM_x_XGBoost_7_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12Ij6w8DPDYl0w6JYCheIJa_bCbLFl9iF
"""

# Commented out IPython magic to ensure Python compatibility.

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

from sklearn.utils import resample
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder

# Untuk pembuatan model
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix

from google.colab import drive
drive.mount('/content/drive/')

url = '/content/drive/MyDrive/Datasetprediksi/data.csv'
df = pd.read_csv(url)
df

df.info()

"""# Menghitung jumlah data kosong pada setiap kolom

"""

df.isna().sum()

"""# Memuat ukuran shape pada dataframe

"""

df.shape

"""# Drop data ID

"""

df.drop(['id'], axis=1, inplace=True)

df

df.describe()

"""# membagi dataset menjadi 2 bagian yaitu kategorial dan numerik

"""

categorical_features = ['diagnosis']
numerical_features = [
                      'radius_mean',
                      'texture_mean',
                      'perimeter_mean',
                      'area_mean',
                      'smoothness_mean',
                      'compactness_mean',
                      'concavity_mean',
                      'concave points_mean',
                      'symmetry_mean',
                      'fractal_dimension_mean',
                      'radius_se',
                      'texture_se',
                      'perimeter_se',
                      'area_se',
                      'smoothness_se',
                      'compactness_se',
                      'concavity_se',
                      'concave points_se',
                      'symmetry_se',
                      'fractal_dimension_se',
                      'radius_worst',
                      'texture_worst',
                      'perimeter_worst',
                      'area_worst',
                      'smoothness_worst',
                      'compactness_worst',
                      'concavity_worst',
                      'concave points_worst',
                      'symmetry_worst',
                      'fractal_dimension_worst'
                      ]

feature = categorical_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
data = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(data)
count.plot(kind='bar', title=feature);

df.hist(bins=50, figsize=(20,15))
plt.show()

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

print("Unique Values for Diagnosis", df['diagnosis'].unique())

oh = OneHotEncoder()

diagnosis_mapping = {'B': 0, 'M': 1}
df['diagnosis'] = df['diagnosis'].map(diagnosis_mapping)

df

df.diagnosis.value_counts()

X = df.drop('diagnosis',axis=1)
y = df['diagnosis']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 5)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

sc=StandardScaler()

X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""Pembuatan Model"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['RandomForest', 'Ligh GBM'])

"""# Algoritma Random Forest"""

RF = RandomForestClassifier()
RF.fit(X_train, y_train)

# Pengujian model terhadap data test
RF_pred = RF.predict(X_test)

"""# Hasil akurasi algoritma Random Forest"""

accuracy_score(y_test, RF_pred)

"""# Evaluasi model algoritma Random Forest"""

RF_cr = classification_report(y_test, RF_pred, output_dict=True)
pd.DataFrame(RF_cr).transpose()

"""#Algoritma Ligth GBM"""

import lightgbm as lgb

# params = {
#     'objective': 'binary',
#     'metric': 'binary_logloss',
#     'boosting_type': 'gbdt',
#     'num_leaves': 31,
#     'learning_rate': 0.05,
#     'feature_fraction': 0.9
# }

# Membuat dan melatih model LightGBM dengan parameter default
LGBM = lgb.LGBMClassifier()
LGBM.fit(X_train, y_train)

# Pengujian model terhadap data test
LGBM2_pred = LGBM.predict(X_test)

"""# Hasil akurasi algoritma Light GBM"""

accuracy_score(y_test, LGBM2_pred)

"""# Evaluasi model algortima Light GBM"""

LGBM_cr = classification_report(y_test, LGBM2_pred, output_dict=True)
pd.DataFrame(LGBM_cr).transpose()

"""# Algoritma XGboost"""

pip install xgboost

import xgboost as xgb

# Inisialisasi model XGBoost
xgb_model = xgb.XGBClassifier()

# Melatih model menggunakan data pelatihan
xgb_model.fit(X_train, y_train)

# Sekarang model XGBoost telah dilatih
# Melakukan prediksi terhadap data test
xgb_pred = xgb_model.predict(X_test)

"""# Hasil akurasi algoritma XGBoost"""

accuracy_score(y_test, xgb_pred)

"""# Evaluasi model algortima XGBoost"""

xgb_cr = classification_report(y_test, xgb_pred, output_dict=True)
pd.DataFrame(xgb_cr).transpose()

"""### perbandingan"""

# Memasukkan hasil laporan klasifikasi model pada dataframe
metrics = pd.DataFrame({'accuracy' : [RF_cr['accuracy'], LGBM_cr['accuracy']],
                        'f1-score_0' : [RF_cr['0']['f1-score'],LGBM_cr['0']['f1-score']],
                        'precision_0' : [RF_cr['0']['precision'],LGBM_cr['0']['precision']],
                        'recall_0' : [RF_cr['0']['recall'],LGBM_cr['0']['recall']],
                        'f1-score_1' : [RF_cr['1']['f1-score'],LGBM_cr['1']['f1-score']],
                        'precision_1' : [RF_cr['1']['precision'],LGBM_cr['1']['precision']],
                        'recall_1' : [RF_cr['1']['recall'],LGBM_cr['1']['recall']]},
                        index=['RF','LGBM'])
multiheader = [('','accuracy'),
               ('0', 'f1-score'),
               ('0', 'precision'),
               ('0', 'recall'),
               ('1', 'f1-score'),
               ('1', 'precision'),
               ('1', 'recall')]
metrics.columns = pd.MultiIndex.from_tuples(multiheader)
# Menampilkan dataframe
metrics

# Memasukkan hasil laporan klasifikasi model pada dataframe
metrics = pd.DataFrame({'accuracy' : [RF_cr['accuracy'], LGBM_cr['accuracy'], xgb_cr['accuracy']],
                        'f1-score_0' : [RF_cr['0']['f1-score'],LGBM_cr['0']['f1-score'],xgb_cr['0']['f1-score']],
                        'precision_0' : [RF_cr['0']['precision'],LGBM_cr['0']['precision'],xgb_cr['0']['precision']],
                        'recall_0' : [RF_cr['0']['recall'],LGBM_cr['0']['recall'],xgb_cr['0']['recall']],
                        'f1-score_1' : [RF_cr['1']['f1-score'],LGBM_cr['1']['f1-score'],xgb_cr['1']['f1-score']],
                        'precision_1' : [RF_cr['1']['precision'],LGBM_cr['1']['precision'],xgb_cr['1']['precision']],
                        'recall_1' : [RF_cr['1']['recall'],LGBM_cr['1']['recall'],xgb_cr['1']['recall']]},
                        index=['RF','LGBM','XGB'])
multiheader = [('','accuracy'),
               ('0', 'f1-score'),
               ('0', 'precision'),
               ('0', 'recall'),
               ('1', 'f1-score'),
               ('1', 'precision'),
               ('1', 'recall')]
metrics.columns = pd.MultiIndex.from_tuples(multiheader)
# Menampilkan dataframe
metrics

RF_cm = confusion_matrix(y_test,RF_pred)
sns.heatmap(RF_cm,annot=True,fmt="d")

LGBM_cm = confusion_matrix(y_test,LGBM2_pred)
sns.heatmap(LGBM_cm,annot=True,fmt="d")

xgb_cm = confusion_matrix(y_test,xgb_pred)
sns.heatmap(xgb_cm,annot=True,fmt="d")